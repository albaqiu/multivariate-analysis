---
title: "Diamonds Data Frame Analysis"
author: "Berta Torrents"
date: "December 2025"
output:
  word_document: default
  pdf_document:
    latex_engine: xelatex
geometry: margin=1in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  results = 'markup',
  message = FALSE,
  warning = FALSE,
  fig.width = 7,
  fig.height = 5
)
```

```{r}
set.seed(12345)

# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

# Libraries
library(dplyr)
library(FactoMineR)
library(MASS)
library(psych)
library(factoextra)
```

## 1. Data preparation

The dataset has been imported with the \emph{read.csv()} function from the \emph{dplyr} library. The first variables named \emph{X} has been eliminated since it corresponds to an index column (it is not an explanatory variable). Moreover, the categorical variables \emph{cut}, \emph{color} and \emph{clarity} have properly been converted into factors.

```{r}
diamonds <- read.csv('diamonds.csv')

diamonds <- diamonds[,-1]

diamonds$cut <- as.factor(diamonds$cut)
diamonds$color <- as.factor(diamonds$color)
diamonds$clarity <- as.factor(diamonds$clarity)

summary(diamonds)
```

Since there are too many observations (53940), it was convenient to perform a random selection ob 500 observations in order to conduct a more manageable and focused study. Note that the means of the numerical variables and the proportion of observations in each category did not variate very much.

```{r}
n <- nrow(diamonds)
indices <- sample(1:n, 500) # Take 500 random indices
diamonds <- diamonds[indices,]

summary(diamonds)
```

## Exploratory data analysis

For each variable, we check: duplicates, existence of zeros, existence of outliers, existence of missing values and we apply transformations if it is needed.

## Numerical variables

Helper function to evaluate missing values and zeros

```{r}
check_numeric <- function(x) {
  list(na      = sum(is.na(x)),
    zeros   = sum(x == 0))
}
```

```{r}
num_vars <- diamonds %>% select_if(is.numeric)

results <- lapply(num_vars, check_numeric)
#results
```
We observe that no numeric variable has NA or zeros

### Carat variable

After analyzing the carat variable, we observe that it doesn't have outliers, but this variable is clearly not normally distributed.
The carat variable is right-skewed, with a long tail towards larger values. After using boxcos function, we see that a log transformation is appropriate to improve symmetry and stabilize variance.

```{r}
# Outliers
boxplot(diamonds$carat, horizontal = T)
varout <- summary(diamonds$carat)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$carat >= usout) | (diamonds$carat <= lsout))
sev_out #0

# Distribution
hist(diamonds$carat,freq=F)
curve(dnorm(x),add=T, col="red") #It is obviously not normally distributed

# Transformation
boxcox(diamonds$carat~1,lambda=seq(-1,1,by=0.1)) # Box-Cox Transformation
diamonds$log_carat <- log(diamonds$carat) # Since lambda = 0 -> logarithmic transformation
boxplot(diamonds$log_carat, horizontal = T) # No outliers

hist(diamonds$log_carat, freq = F) # Is log_carat normally distributed?
m = mean(diamonds$log_carat)
std = sd(diamonds$log_carat)
curve(dnorm(x,m,std),col="red",lwd=2,add=T)
```

### Depth variable

The depth variable has 2 extreme outliers, which we removed. Then, we observe that the depth variable has an approximately symmetric, bell-shaped distribution, so no transformation is needed.

```{r}
# Outliers
boxplot(diamonds$depth, horizontal = T)
varout <- summary(diamonds$depth)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$depth >= usout) | (diamonds$depth <= lsout))
abline(v=usout,col='orange')
abline(v=lsout,col='orange')
sev_out #[1] 462 467
diamonds <- diamonds[-sev_out,] # Remove extreme outliers

# Distribution
hist(diamonds$depth,freq=F)
m = mean(diamonds$depth)
std = sd(diamonds$depth)
curve(dnorm(x,m,std),add=T, col="red")
```


### Table variable

The variable table has 1 outlier, after removing it we see the distribution of this variable: it's almost symmetric with mild right skewness. Since its shape is already close to normal and a transformation would not provide meaningful improvement, no transformation is applied.

```{r}
# Outliers
boxplot(diamonds$table, horizontal = TRUE)
varout <- summary(diamonds$table)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$table >= usout) | (diamonds$table <= lsout))
abline(v=usout,col='orange')
abline(v=lsout,col='orange')
sev_out #206
diamonds <- diamonds[-sev_out,] # Remove extreme outliers

# Distribution
hist(diamonds$table,freq=F)
m = mean(diamonds$table)
std = sd(diamonds$table)
curve(dnorm(x,m,std),add=T, col="red")
```

### Price variable

The variable price doesn't have severe outliers, but we can observe a long tail at the right of the boxplot indicating potential mild outliers.

Using the histogram, it has a right skewed distribution, which can be improved by a log transformation to reduce its skewness and stabilize variance, and based on the boxcox, we apply a this transformation because $\lambda=0$.

After applying the log transformation, the distribution becomes more symmetric and closer to a bell-shaped form.

```{r}
# Outliers
boxplot(diamonds$price, horizontal = T)
varout <- summary(diamonds$price)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$price > usout) | (diamonds$price < lsout))
abline(v=usout,col='orange')
abline(v=lsout,col='orange')
sev_out #0

# Distribution
hist(diamonds$price, freq = F) # A log transformation could be applied to reduce skewness and stabilize variance
m = mean(diamonds$price)
std = sd(diamonds$price)
curve(dnorm(x,m,std),add=T, col="red")

# Logarithmic transformation
boxcox(diamonds$price~1,lambda=seq(-1,1,by=0.1)) # Box-Cox Transformation
diamonds$log_price <- log(diamonds$price) # Since lambda = 0 -> logarithmic transformation
boxplot(diamonds$log_price, horizontal = T) # No outliers
hist(diamonds$log_price, freq = F) # Is log_price normally distributed?
m = mean(diamonds$log_price)
std = sd(diamonds$log_price)
curve(dnorm(x,m,std),col="red",lwd=2,add=T) 
```

### x variable
The variable x is right-skewed, applying a logarithmic transformation reduces this skewness and produces a more symmetric distribution, as shown in the histogram of log_x. Although the original variable does not show severe outliers and can be used in its raw form for descriptive analysis, the log transformation improves distributional symmetry and is beneficial for subsequent statistical modeling. Therefore, the logarithmic version is retained for later analysis.

```{r}
# Outliers
boxplot(diamonds$x, horizontal = T)
varout <- summary(diamonds$x)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$x > usout) | (diamonds$x < lsout))
abline(v=usout,col='orange')
abline(v=lsout,col='orange')
sev_out #0

# Distribution
hist(diamonds$x, freq = F)
m = mean(diamonds$x)
std = sd(diamonds$x)
curve(dnorm(x,m,std),add=T, col="red")

# Logarithmic transformation
boxcox(diamonds$x~1,lambda=seq(-1,1,by=0.1)) # Box-Cox Transformation
diamonds$log_x <- log(diamonds$x) # Since lambda = 0 -> logarithmic transformation
boxplot(diamonds$log_x, horizontal = T) # No outliers
hist(diamonds$log_x, freq = F) # Is log_x normally distributed?
m = mean(diamonds$log_x)
std = sd(diamonds$log_x)
curve(dnorm(x,m,std),col="red",lwd=2,add=T) 
```

### y variable
The variable y, is also right-skewed, although the distribution does not show severe outliers, the skewness indicates that the variable is not symmetric. Box–Cox analysis suggests a transformation close to λ = 0, a logarithmic transformation is appropriate. The transformed variable (log_y) shows a much more symmetric, bell-shaped distribution.

```{r}
# Outliers
boxplot(diamonds$y, horizontal = T)
varout <- summary(diamonds$y)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$y > usout) | (diamonds$y < lsout))
abline(v=usout,col='orange')
abline(v=lsout,col='orange')
sev_out #0

# Distribution
hist(diamonds$y, freq = F)
m = mean(diamonds$y)
std = sd(diamonds$y)
curve(dnorm(x,m,std),add=T, col="red")

# Logarithmic transformation
boxcox(diamonds$y~1,lambda=seq(-1,1,by=0.1)) # Box-Cox Transformation
diamonds$log_y <- log(diamonds$y) # Since lambda is near 0 -> logarithmic transformation
boxplot(diamonds$log_y, horizontal = T) # No outliers
hist(diamonds$log_y, freq = F) # Is log_y normally distributed?
m = mean(diamonds$log_y)
std = sd(diamonds$log_y)
curve(dnorm(x,m,std),col="red",lwd=2,add=T)
```

### z variable

Similar as x and y, the variable z is also right-skewed, although the distribution does not show severe outliers, the skewness indicates deviation from symmetry. Box–Cox analysis suggests a transformation close to λ = 0. After applying the log transformation, the distribution is more symmetric and bell-shaped.

```{r}
# Outliers
boxplot(diamonds$z, horizontal = T)
varout <- summary(diamonds$z)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$z > usout) | (diamonds$z < lsout))
abline(v=usout,col='orange')
abline(v=lsout,col='orange')
sev_out #0

# Distribution
hist(diamonds$z, freq = F) # A log transformation could be applied to reduce skewness and stabilize variance
m = mean(diamonds$z)
std = sd(diamonds$z)
curve(dnorm(x,m,std),add=T, col="red")

# Logarithmic transformation
boxcox(diamonds$z~1,lambda=seq(-1,1,by=0.1)) # Box-Cox Transformation
diamonds$log_z <- log(diamonds$z) # Since lambda is near 0 -> logarithmic transformation
boxplot(diamonds$log_z, horizontal = T) # No outliers
hist(diamonds$log_z, freq = F) # Is log_z normally distributed?
m = mean(diamonds$log_z)
std = sd(diamonds$log_z)
curve(dnorm(x,m,std),col="red",lwd=2,add=T)
```

## Categorical variables

### Cut variable 

Since cut variable is a factor, we don't check its boxplot or its zeros, instead we observe its levels. The level with highest frequency is Ideal, while level Fair has only 9 observations, but this is possible, so it's not an outlier.

```{r}
# Check NA (we don't need to check 0s)
cat("Missing values in cut:", sum(is.na(diamonds$cut)), "\n") #0

# Distribution
summary(diamonds$cut)
barplot(summary(diamonds$cut), main="Diamond Cut Quality")
```

### Color variable

Same as before, we analyse the different levels of color. The most frequent is G color grade and the less frequent is J color grade, meaning diamonds with a noticeable tint are less common in the dataset.

```{r}
# Check NA
cat("Missing values in color:", sum(is.na(diamonds$color)), "\n") #0

# Distribution
summary(diamonds$color)
barplot(summary(diamonds$color), main="Diamond Color")
```

### Clarity variable

The diamond clarity distribution is more frequent for the SI1 and VS2 grades, so the sample is composed mostly of slightly-to-very slightly included stones.

```{r}
# Check NA 
cat("Missing values in clarity:", sum(is.na(diamonds$clarity)), "\n") #0

# Distribution
summary(diamonds$clarity)
barplot(summary(diamonds$clarity), main="Diamond Clarity")
```

In conclusion, we have removed 3 observations and transformed the variables carat, price, x, y, z with logarithmic tranformation, and we'll work with this dataframe:

```{r}
#diamonds <- diamonds[,c(2:6,11:15)]
```

### VARAIBLE CREATION????

## Correlations between numeric variables

```{r}
numeric_vars <- diamonds[ , sapply(diamonds, is.numeric)] # Get numeric variables

cor_matrix <- cor(numeric_vars)
print(cor_matrix)

library(corrplot)
corrplot(cor_matrix, method = "color", addCoef.col = "black", title = "Correlation Plot of Numeric Variables") 

# Variables seem to be higher correlated, 
# but scatter plots must be performed to verify this correlation

pairs(numeric_vars, main="Scatterplot Matrix of Numeric Variables")

# Obs: Thanks to the log transformation of carat and price, now there is a higher correlation between this two transformed variables and the rest 

numeric_vars <- numeric_vars[ , !colnames(numeric_vars) %in% c("price", "carat")] # We will work with the logarithmic transfroamtion of price and carat

# Obs: Except from table and depth, the rest of the variables have a strong positive correlation

cortest.bartlett(cor_matrix, nrow(diamonds)) # p-value < 0.05 -> reject H0 -> corr_matrix != Id

# Apply KMO function to see if data is factorable (function written by Prof. Shigenobu Aok.)

kmo <- function(x)
{
  x <- subset(x, complete.cases(x))       # Omit missing values
  r <- cor(x)                             # Correlation matrix
  r2 <- r^2                               # Squared correlation coefficients
  i <- solve(r)                           # Inverse matrix of correlation matrix
  d <- diag(i)                            # Diagonal elements of inverse matrix
  p2 <- (-i/sqrt(outer(d, d)))^2          # Squared partial correlation coefficients
  diag(r2) <- diag(p2) <- 0               # Delete diagonal elements
  KMO <- sum(r2)/(sum(r2)+sum(p2))
  MSA <- colSums(r2)/(colSums(r2)+colSums(p2))
  return(list(KMO=KMO, MSA=MSA))
}

# KMO index
kmo(numeric_vars) # Is higher than 0.5 -> data is factorable
```

# Part 2: Multivariant analysis

## Principal components analysis

```{r}
diamonds.pca <- PCA(numeric_vars, graph = T)

diamonds.pca$eig # Taking only two dimensions, 89% of the variability can be explain

diamonds.pca$var$coord
diamonds.pca$var$cos2
diamonds.pca$var$contrib
# Fist dimension is basically explained by "x", "y", "z", "log_carat", "log_price" variables,
# and they are positively correlated with the dimension. 
# In fact, each of the previous variables explains around 19% of dimension 1 variation.
# In other words, first dimension is explained by the size–related and variables.
# The bigger and more expensive the diamond is, the higher is the first dimension value.

# Second dimension is basically explained by "depth" and "table" variables,
# and it is positively correlated with depth but negatively correlated with table.
# In fact, each of the previous variables explains around 44-53% of dimension 2 variation.
# In other words, second dimension is explained by the proportional shape.
# The deeper and narrower the diamond is, the higher is the second dimension value.



# pca_hep<-PCA(heptathlon, quanti.sup = 8) #Get rid of score variable because is target



# Since some variables are not very correlated with the rest, ç
# and PCA results are affected by this variables,
# let's repeat the PCA using only the correlated variables

```

## Multidimensional scaling

## Correspondance analysis ??????

## Multiple correspondance analysis

## Cluster analysis

### Profiling
