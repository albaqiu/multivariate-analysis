---
title: "Diamonds Data Frame Analysis"
author: "Berta Torrents"
date: "December 2025"
output:
  word_document: default
  pdf_document:
    latex_engine: xelatex
geometry: margin=1in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  results = 'markup',
  message = FALSE,
  warning = FALSE,
  fig.width = 7,
  fig.height = 5
)
```

```{r}
set.seed(12345)

# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

# Libraries
library(dplyr)
library(FactoMineR)
library(MASS)
library(psych)
library(factoextra)
```

## 1. Data preparation

The dataset has been imported with the \emph{read.csv()} function from the \emph{dplyr} library. The first variables named \emph{X} has been eliminated since it corresponds to an index column (it is not an explanatory variable). Moreover, the categorical variables \emph{cut}, \emph{color} and \emph{clarity} have properly been converted into factors.

```{r}
diamonds <- read.csv('diamonds.csv')

diamonds <- diamonds[,-1]

diamonds$cut <- as.factor(diamonds$cut)
diamonds$color <- as.factor(diamonds$color)
diamonds$clarity <- as.factor(diamonds$clarity)

summary(diamonds)
```

Since there are too many observations (53940), it was convenient to perform a random selection ob 500 observations in order to conduct a more manageable and focused study. Note that the means of the numerical variables and the proportion of observations in each category did not variate very much.

```{r}
n <- nrow(diamonds)
indices <- sample(1:n, 500) # Take 500 random indices
diamonds <- diamonds[indices,]

summary(diamonds)
```

## Exploratory data analysis

For each variable, we check: duplicates, existence of zeros, existence of outliers, existence of missing values and we apply transformations if it is needed.

## Numerical variables

### Carat variable

After analyzing the carat variable, we observe that it doesn't have missing values, zeros or outliers, but this variable is not normally distributed, and after applying the log transformation, it's still not normal.

```{r}
# Check NA and zeros
cat("Missing values in carat:", sum(is.na(diamonds$carat)), "\n") #0
cat("Number of zeros in carat:", sum(diamonds$carat == 0), "\n") #0

# Outliers
boxplot(diamonds$carat, horizontal = T)
varout <- summary(diamonds$carat)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$carat > usout) | (diamonds$carat < lsout))
sev_out #0

# Distribution
hist(diamonds$carat,freq=F)
curve(dnorm(x),add=T, col="red") #It is obviously not normally distributed

# Transformation
boxcox(diamonds$carat~1,lambda=seq(-1,1,by=0.1)) # Box-Cox Transformation
diamonds$log_carat <- log(diamonds$carat) # Since lambda = 0 -> logarithmic transformation
boxplot(diamonds$log_carat, horizontal = T) # No outliers

hist(diamonds$log_carat, freq = F) # Is log_carat normally distributed?
m = mean(diamonds$log_carat)
std = sd(diamonds$log_carat)
curve(dnorm(x,m,std),col="red",lwd=2,add=T)

shapiro.test(diamonds$log_carat) #p-value < 0.05 -> log_carat is not normally distributed
```

### Depth variable

The depth variable has no NA and no zeros, but it has 2 extreme outliers, which we removed.

Analyzing the results of the shapiro test, data was not normally distributed, but we don't apply transformations because $\lambda=0.5$ is the lower bound of the confidence interval and the optimal transformation is $\lambda \approx 1.0$, which means applying no transformation.

```{r}
# Check NA and zeros
cat("Missing values in depth:", sum(is.na(diamonds$depth)), "\n") #0
cat("Number of zeros in depth:", sum(diamonds$depth == 0), "\n") #0

# Outliers
boxplot(diamonds$depth, horizontal = T)
varout <- summary(diamonds$depth)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$depth > usout) | (diamonds$depth < lsout))
abline(v=usout,col='orange')
abline(v=lsout,col='orange')
sev_out #[1] 462 467
diamonds <- diamonds[-sev_out,] # Remove extreme outliers

# Distribution
hist(diamonds$depth,freq=F)
m = mean(diamonds$depth)
std = sd(diamonds$depth)
curve(dnorm(x,m,std),add=T, col="red")
shapiro.test(diamonds$depth) #p-value < 0.01 -> not normally distirbuted

# Transformation
boxcox(diamonds$depth~1,lambda=seq(-1,1,by=0.1)) # Box-Cox Transformation
# no transformation is needed
```


### Table variable

The variable table has no NA, zeros or outliers. We won't apply any transformation!!??

```{r}
# Check NA and zeros
cat("Missing values in table:", sum(is.na(diamonds$table)), "\n") #0
cat("Number of zeros in table:", sum(diamonds$table == 0), "\n") #0

# Outliers
boxplot(diamonds$table, horizontal = TRUE)
varout <- summary(diamonds$table)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$table > usout) | (diamonds$table < lsout))
abline(v=usout,col='orange')
abline(v=lsout,col='orange')
sev_out #0


# Distribution
hist(diamonds$table,freq=F)
m = mean(diamonds$table)
std = sd(diamonds$table)
curve(dnorm(x,m,std),add=T, col="red")
shapiro.test(diamonds$table) #p-value < 0.01 -> not normally distributed

# Transformation
boxcox(diamonds$table~1,lambda=seq(-1,1,by=0.1)) # Box-Cox Transformation
# Reciprocal transformation based on the Box-Cox suggestion (lambda = -1) --> jo no faria cap
#diamonds$reci_table <- 1 / diamonds$table
#hist(diamonds$reci_table)
#m = mean(diamonds$reci_table)
#std = sd(diamonds$reci_table)
#curve(dnorm(x,m,std),add=T, col="red")
#shapiro.test(diamonds$reci_table) #p-value < 0.01 -> not normally distirbuted
```

### Price variable

The `price` variable has no missing values and no outliers.

Analyzing the results of the shapiro test, data was not normally distributed, and based on the boxcox, we apply a logarithmic transformations because $\lambda=0$.

```{r}
# Check NA and zeros
cat("Missing values in price:", sum(is.na(diamonds$price)), "\n") #0
cat("Number of zeros in price:", sum(diamonds$price == 0), "\n") #0

# Outliers
boxplot(diamonds$price, horizontal = T)
varout <- summary(diamonds$price)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$price > usout) | (diamonds$price < lsout))
abline(v=usout,col='orange')
abline(v=lsout,col='orange')
sev_out #0

# Distribution
hist(diamonds$price, freq = F) # A log transformation could be applied to reduce skewness and stabilize variance

# Logarithmic transformation
boxcox(diamonds$price~1,lambda=seq(-1,1,by=0.1)) # Box-Cox Transformation
diamonds$log_price <- log(diamonds$price) # Since lambda = 0 -> logarithmic transformation

boxplot(diamonds$log_price, horizontal = T) # No outliers
varout <- summary(diamonds$log_price)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
sev_out <- which((diamonds$log_price > usout) | (diamonds$log_price < lsout))
abline(v=usout,col='orange')
abline(v=lsout,col='orange')
sev_out #0

hist(diamonds$log_price, freq = F) # Is log_price normally distributed?
m = mean(diamonds$log_price)
std = sd(diamonds$log_price)
curve(dnorm(x,m,std),col="red",lwd=2,add=T) 

shapiro.test(diamonds$log_price) #p-value < 0.05 -> log price is not normally distributed
```

### x variable

```{r}
boxplot(diamonds$x, horizontal = T) # No outliers

hist(diamonds$x, freq = F) # Is x normally distributed?
m = mean(diamonds$x)
std = sd(diamonds$x)
curve(dnorm(x,m,std),col="red",lwd=2,add=T) 

shapiro.test(diamonds$x) #p-value < 0.05 -> x is not normally distributed
```

### y variable

```{r}
boxplot(diamonds$y, horizontal = T) # No outliers

hist(diamonds$y, freq = F) # Is y normally distributed?
m = mean(diamonds$y)
std = sd(diamonds$y)
curve(dnorm(x,m,std),col="red",lwd=2,add=T)

shapiro.test(diamonds$y) #p-value < 0.05 -> y is not normally distributed
```

### z variable

```{r}
boxplot(diamonds$z, horizontal = T) # No outliers

hist(diamonds$z, freq = F) # Is z normally distributed?
m = mean(diamonds$z)
std = sd(diamonds$z)
curve(dnorm(x,m,std),col="red",lwd=2,add=T)

shapiro.test(diamonds$z) #p-value < 0.05 -> z is not normally distributed


nrow(diamonds) # Only two outlier observations have been removed
```


## Categorical variables

### Cut variable 

Since cut variable is a factor, we don't check its boxplot or its zeros, instead we observe its levels. The level with highest frequency is Ideal, while level Fair has only 9 observations, but this is possible, so it's not an outlier.

```{r}
# Check NA (we don't need to check 0s)
cat("Missing values in cut:", sum(is.na(diamonds$cut)), "\n") #0

# Distribution
summary(diamonds$cut)
barplot(summary(diamonds$cut), main="Diamond Cut Quality")
```

### Color variable

Same as before, we analyse the different levels of color. The most frequent is G color grade and the less frequent is J color grade, meaning diamonds with a noticeable tint are less common in the dataset. It can be mapped to 1,2,3..??? (es una escala)

```{r}
# Check NA
cat("Missing values in color:", sum(is.na(diamonds$color)), "\n") #0

# Distribution
summary(diamonds$color)
barplot(summary(diamonds$color), main="Diamond Color")
```

### Clarity variable

The diamond clarity distribution is more frequent for the SI1 and VS2 grades, so the sample is composed mostly of slightly-to-very slightly included stones. It can be mapped to 1,2,3..??? (es una escala)

```{r}
# Check NA 
cat("Missing values in clarity:", sum(is.na(diamonds$clarity)), "\n") #0

# Distribution
summary(diamonds$clarity)
barplot(summary(diamonds$clarity), main="Diamond Clarity")
```

### VARAIBLE CREATION????

## Correaltions between numeric variables

```{r}
numeric_vars <- diamonds[ , sapply(diamonds, is.numeric)] # Get numeric variables

cor_matrix <- cor(numeric_vars)
print(cor_matrix)

library(corrplot)
corrplot(cor_matrix, method = "color", addCoef.col = "black", title = "Correlation Plot of Numeric Variables") 

# Variables seem to be higher correlated, 
# but scatter plots must be performed to verify this correlation

pairs(numeric_vars, main="Scatterplot Matrix of Numeric Variables")

# Obs: Thanks to the log transformation of carat and price, now there is a higher correlation between this two transformed variables and the rest 

numeric_vars <- numeric_vars[ , !colnames(numeric_vars) %in% c("price", "carat")] # We will work with the logarithmic transfroamtion of price and carat

# Obs: Except from table and depth, the rest of the variables have a strong positive correlation

cortest.bartlett(cor_matrix, nrow(diamonds)) # p-value < 0.05 -> reject H0 -> corr_matrix != Id

# Apply KMO function to see if data is factorable (function written by Prof. Shigenobu Aok.)

kmo <- function(x)
{
  x <- subset(x, complete.cases(x))       # Omit missing values
  r <- cor(x)                             # Correlation matrix
  r2 <- r^2                               # Squared correlation coefficients
  i <- solve(r)                           # Inverse matrix of correlation matrix
  d <- diag(i)                            # Diagonal elements of inverse matrix
  p2 <- (-i/sqrt(outer(d, d)))^2          # Squared partial correlation coefficients
  diag(r2) <- diag(p2) <- 0               # Delete diagonal elements
  KMO <- sum(r2)/(sum(r2)+sum(p2))
  MSA <- colSums(r2)/(colSums(r2)+colSums(p2))
  return(list(KMO=KMO, MSA=MSA))
}

# KMO index
kmo(numeric_vars) # Is higher than 0.5 -> data is factorable
```

# Part 2: Multivariant analysis

## Principal components analysis

```{r}
diamonds.pca <- PCA(numeric_vars, graph = T)

diamonds.pca$eig # Taking only two dimensions, 89% of the variability can be explain

diamonds.pca$var$coord
diamonds.pca$var$cos2
diamonds.pca$var$contrib
# Fist dimension is basically explained by "x", "y", "z", "log_carat", "log_price" variables,
# and they are positively correlated with the dimension. 
# In fact, each of the previous variables explains around 19% of dimension 1 variation.
# In other words, first dimension is explained by the size–related and variables.
# The bigger and more expensive the diamond is, the higher is the first dimension value.

# Second dimension is basically explained by "depth" and "table" variables,
# and it is positively correlated with depth but negatively correlated with table.
# In fact, each of the previous variables explains around 44-53% of dimension 2 variation.
# In other words, second dimension is explained by the proportional shape.
# The deeper and narrower the diamond is, the higher is the second dimension value.



# pca_hep<-PCA(heptathlon, quanti.sup = 8) #Get rid of score variable because is target



# Since some variables are not very correlated with the rest, ç
# and PCA results are affected by this variables,
# let's repeat the PCA using only the correlated variables

```

## Multidimensional scaling

## Correspondance analysis ??????

## Multiple correspondance analysis

## Cluster analysis

### Profiling
